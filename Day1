# ğŸ¤– LLM ì›ë¦¬ + OpenAI Chat Completion API í™œìš©

---

## 1. LLM ê¸°ë³¸ ê°œë…

### ğŸ§  LLM(Large Language Model)ì˜ ìƒì„± ì›ë¦¬

**LLMì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?**
- **íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°**: ëŒ€í™”í˜• AIì˜ í•µì‹¬ ì•„í‚¤í…ì²˜
- **í† í° ì˜ˆì¸¡**: ë‹¤ìŒì— ì˜¬ ê°€ì¥ ì ì ˆí•œ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡
- **í•™ìŠµ ë°©ì‹**: ì¸í„°ë„·ì˜ ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ì „ í›ˆë ¨

**í•µì‹¬ í”„ë¡œì„¸ìŠ¤**
1. **í† í°í™”**: í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ë‹¨ìœ„(í† í°)ë¡œ ë¶„í• 
2. **í™•ë¥  ê³„ì‚°**: ê° í† í°ì´ ë‹¤ìŒì— ì˜¬ í™•ë¥  ê³„ì‚°
3. **í† í° ìƒì„±**: í™•ë¥  ë¶„í¬ì— ë”°ë¼ í† í° ì„ íƒ
4. **ë°˜ë³µ**: ì¢…ë£Œ ì¡°ê±´ê¹Œì§€ ê³¼ì • ë°˜ë³µ


**íŠ¸ëœìŠ¤í¬ë¨¸**:
- **ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°**: ì…ë ¥ê³¼ ì¶œë ¥ì„ ë™ì‹œì— ì²˜ë¦¬
- **ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜**: ì…ë ¥ì˜ ëª¨ë“  ë¶€ë¶„ì„ ë™ì‹œì— ê³ ë ¤í•˜ì—¬ ì¤‘ìš”í•œ ì •ë³´ì— ì§‘ì¤‘


<div style="text-align: left; font-size: 12px;">
<div style="text-align: center;">
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Transformer%2C_full_architecture.png/440px-Transformer%2C_full_architecture.png"
        alt="Illustrations for the Transformer and attention mechanism showing the full Transformer architecture"
        width="600"
        style="border: 0;">
</div>

**Image Title:** Transformer Architecture Illustration  
**Source:** [GitHub - DL Visuals](https://github.com/dvgodoy/dl-visuals/?tab=readme-ov-file)  
**License:** [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/)  
**Author(s):** dvgodoy  

</div>



---

## 2. OpenAI API í•µì‹¬ ê°œë…

### ğŸ”§ ì£¼ìš” êµ¬ì„± ìš”ì†Œ

**1. ë©”ì‹œì§€ í˜•ì‹**

  ```python
  messages = [
      {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
      {"role": "user", "content": "íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”."},
      {"role": "assistant", "content": "sort() ë©”ì„œë“œë‚˜ sorted() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."}
  ]
  ```

**2. í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ì£¼ìš” ëª¨ë¸ (2025ë…„ ê¸°ì¤€)**

  - **gpt-4.1**: ìµœê³  ì„±ëŠ¥, ë³µì¡í•œ ì‘ì—…ìš©
  - **gpt-4.1-mini**: ë¹ ë¥¸ ì†ë„, ë¹„ìš© íš¨ìœ¨ì 
  - **gpt-4.1-nano**: ì´ˆê³ ì†, ìµœì € ë¹„ìš©
  - **o3, o4-mini**: ë³µì¡í•œ ì¶”ë¡  ì‘ì—…ìš©
  - **gpt-4o**: ë©€í‹°ëª¨ë‹¬ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤)

**3. API ì‘ë‹µ êµ¬ì¡°**

  ```json
  {
    "id": "chatcmpl-...",
    "object": "chat.completion",
    "model": "gpt-4.1-mini",
    "choices": [
      {
        "message": {
          "role": "assistant", 
          "content": "ìƒì„±ëœ í…ìŠ¤íŠ¸"
        }
      }
    ],
    "usage": {
      "prompt_tokens": 10,
      "completion_tokens": 50,
      "total_tokens": 60
    }
  }
  ```

---

## 3. í™˜ê²½ ì„¤ì •


### ğŸš€ uv í”„ë¡œì íŠ¸ ì„¤ì •
- **í”„ë¡œì íŠ¸ ìƒì„±**: `uv init [í”„ë¡œì íŠ¸ëª…]`
- **ê°€ìƒí™˜ê²½ ìƒì„±**: `uv venv --python=3.12`
- **ê°€ìƒí™˜ê²½ í™œì„±í™”**: `.venv/bin/activate` (Unix) ë˜ëŠ” `.venv\Scripts\activate` (Windows)


### ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# uv ì‚¬ìš© (ê¶Œì¥)
uv add uv add langchain langchain_openai python-dotenv ipykernel

# pip ì‚¬ìš©
pip install uv add langchain langchain_openai python-dotenv ipykernel
```

### ğŸ” API í‚¤ ì„¤ì •
```python
# .env íŒŒì¼ ìƒì„±
OPENAI_API_KEY=your_api_key_here

# Pythonì—ì„œ ë¡œë“œ
from dotenv import load_dotenv
import os

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
```


---

## 4. ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±

### ğŸ’¡ ê°„ë‹¨í•œ ì§ˆì˜-ì‘ë‹µ
from openai import OpenAI

# í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = OpenAI()

# ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±
response = client.chat.completions.create(
    model="gpt-4.1-mini",
    messages=[
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œê·¼í•œ í”„ë¡œê·¸ë˜ë° íŠœí„°ì…ë‹ˆë‹¤."},
        {"role": "user", "content": "íŒŒì´ì¬ í•¨ìˆ˜ë€ ë¬´ì—‡ì¸ê°€ìš”?"}
    ],
    temperature=0.7,
    max_tokens=300
)

# ê²°ê³¼ ì¶œë ¥
print(response.choices[0].message.content)
### ğŸ¯ ì½”ë“œ ì„¤ëª…ê¸°
def explain_code(code):
    response = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "system", "content": "ì½”ë“œë¥¼ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
            {"role": "user", "content": f"ì´ ì½”ë“œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n\n{code}"}
        ],
        temperature=0.3
    )
    return response.choices[0].message.content

# ì‚¬ìš© ì˜ˆì‹œ
code = """
def quicksort(arr):
    if len(arr) <= 1:
        return arr
    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    return quicksort(left) + middle + quicksort(right)
"""

explanation = explain_code(code)
print(explanation)
---

## 5. êµ¬ì¡°í™”ëœ ì¶œë ¥

### ğŸ“Š JSON ìŠ¤í‚¤ë§ˆ í™œìš©

import json

# ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì˜ˆì œ
response = client.chat.completions.create(
    model="gpt-4.1",
    messages=[
        {
            "role": "system", 
            "content": "ìƒí’ˆ ì •ë³´ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì—¬ JSON í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."
        },
        {
            "role": "user", 
            "content": "ì‚¼ì„± ê°¤ëŸ­ì‹œ S24 Ultra 512GB (í‹°íƒ€ëŠ„ ê·¸ë ˆì´) - 1,698,400ì›"
        }
    ],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "product_schema",
            "schema": {
                "type": "object",
                "properties": {
                    "brand": {"type": "string", "description": "ë¸Œëœë“œëª…"},
                    "model": {"type": "string", "description": "ëª¨ë¸ëª…"},
                    "storage": {"type": "string", "description": "ì €ì¥ìš©ëŸ‰"},
                    "color": {"type": "string", "description": "ìƒ‰ìƒ"},
                    "price": {"type": "number", "description": "ê°€ê²©(ì›)"},
                    "category": {"type": "string", "description": "ì œí’ˆ ì¹´í…Œê³ ë¦¬"}
                },
                "required": ["brand", "model", "price"]
            }
        }
    }
)

# JSON íŒŒì‹±
product_data = json.loads(response.choices[0].message.content)
print(json.dumps(product_data, indent=2, ensure_ascii=False))
---

## 6. ë§¤ê°œë³€ìˆ˜ ìµœì í™”

### âš™ï¸ í•µì‹¬ ë§¤ê°œë³€ìˆ˜ ê°€ì´ë“œ

| ë§¤ê°œë³€ìˆ˜ | ë²”ìœ„ | ìš©ë„ | ì¶”ì²œê°’ |
|---------|------|------|--------|
| `temperature` | 0~2 | ì°½ì˜ì„± ì¡°ì ˆ | 0.3 (ì •í™•ì„±), 0.7 (ê· í˜•), 1.2 (ì°½ì˜ì„±) |
| `top_p` | 0~1 | ì‘ë‹µ ë‹¤ì–‘ì„± | 0.9 (ê¸°ë³¸), 0.3 (ì§‘ì¤‘ì ) |
| `max_tokens` | 1~8192+ | ìµœëŒ€ ê¸¸ì´ | ì‘ì—…ì— ë”°ë¼ ì¡°ì ˆ |
| `frequency_penalty` | -2~2 | ë°˜ë³µ ì–µì œ | 0.3~0.6 |
| `presence_penalty` | -2~2 | ìƒˆ ì£¼ì œ ë„ì… | 0.3~0.6 |
### ğŸ¨ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„¤ì •

**1. ì •í™•í•œ ì •ë³´ ì œê³µ**
response = client.chat.completions.create(
    model="gpt-4.1-mini",
    messages=[{"role": "user", "content": "íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ ë©”ì„œë“œë“¤ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."}],
    temperature=0.2,  # ë‚®ì€ ì°½ì˜ì„±
    top_p=0.3,        # ì§‘ì¤‘ì  ì‘ë‹µ
    max_tokens=500
)

print(response.choices[0].message.content)
**2. ì°½ì˜ì  ê¸€ì“°ê¸°**
response = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "ìš°ì£¼ ì •ê±°ì¥ì—ì„œì˜ í•˜ë£¨ë¥¼ ì†Œì„¤ë¡œ ì¨ì£¼ì„¸ìš”."}],
    temperature=1.1,  # ë†’ì€ ì°½ì˜ì„±
    top_p=0.9,        # ë‹¤ì–‘í•œ í‘œí˜„
    max_tokens=1000,
    frequency_penalty=0.5  # ë°˜ë³µ ë°©ì§€
)

print(response.choices[0].message.content)
**3. ì½”ë“œ ìƒì„±**
response = client.chat.completions.create(
    model="gpt-4.1-mini",
    messages=[{"role": "user", "content": "ì›¹ ìŠ¤í¬ë˜í•‘ì„ ìœ„í•œ Python í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”."}],
    temperature=0.4,  # ì•½ê°„ì˜ ì°½ì˜ì„±
    max_tokens=800
)

print(response.choices[0].message.content)
---

## 7. ì‹¤ìŠµ ë¬¸ì œ

**ë¬¸ì œ 1: ì–¸ì–´ ë²ˆì—­ê¸° ë§Œë“¤ê¸°**
def translator(text, target_language):
    # TODO: OpenAI APIë¥¼ ì‚¬ìš©í•´ì„œ ë²ˆì—­ í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”
    pass

# í…ŒìŠ¤íŠ¸
result = translator("ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”!", "ì˜ì–´")
print(result)  # ì˜ˆìƒ ì¶œë ¥: Hello, the weather is nice today!
**ë¬¸ì œ 2: ê°ì • ë¶„ì„ê¸°**
def analyze_sentiment(text):
    # TODO: í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“œì„¸ìš”
    # ë°˜í™˜ í˜•íƒœ: {"sentiment": "positive/negative/neutral", "confidence": 0.85}
    # íŒíŠ¸: client.chat.completions.create()ë¥¼ ì‚¬ìš©í•˜ê³  response_formatìœ¼ë¡œ JSON ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•˜ì„¸ìš”
    pass

# í…ŒìŠ¤íŠ¸
result = analyze_sentiment("ì˜¤ëŠ˜ ì‹œí—˜ì„ ì˜ ë´¤ì–´ìš”! ì •ë§ ê¸°ì©ë‹ˆë‹¤.")
print(result)
# ì˜ˆìƒ ì¶œë ¥: {'sentiment': 'positive', 'confidence': 0.95}


---

## ğŸ”— ìœ ìš©í•œ ë§í¬
- [OpenAI API ê³µì‹ ë¬¸ì„œ](https://platform.openai.com/docs)
- [OpenAI í† í° ê³„ì‚°ê¸°](https://platform.openai.com/tokenizer)
- [í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°€ì´ë“œ](https://platform.openai.com/docs/guides/prompt-engineering)

---
### ì‹¤ìŠµ 7-1 ë‹µì•ˆ

def translator(text, target_language):
    response = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "user", "content": f"Translate the following text to {target_language}: {text}"}
        ],
        temperature=0.5,
        max_tokens=600
    )
    return response.choices[0].message.content

# í…ŒìŠ¤íŠ¸
result = translator("ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”!", "ì˜ì–´")
print(result)  # ì˜ˆìƒ ì¶œë ¥: Hello, the weather is nice today!

### ì‹¤ìŠµ 7-2 ë‹µì•ˆ

def analyze_sentiment(text):
    # TODO: í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“œì„¸ìš”
    # ë°˜í™˜ í˜•íƒœ: {"sentiment": "positive/negative/neutral", "confidence": 0.85}
    response = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "user", "content": f"Analyze the sentiment of this text: {text}"}
        ],
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "sentiment_schema",
                "schema": {
                    "type": "object",
                    "properties": {
                        "sentiment": {
                            "type": "string",
                            "enum": ["positive", "negative", "neutral"],
                            "description": "ê°ì • ë¶„ë¥˜"
                        },
                        "confidence": {
                            "type": "number",
                            "minimum": 0,
                            "maximum": 1,
                            "description": "ë¶„ì„ ì‹ ë¢°ë„ (0~1)"
                        }
                    },
                    "required": ["sentiment", "confidence"]
                }
            }
        },
        temperature=0.3
    )
    return json.loads(response.choices[0].message.content)

# í…ŒìŠ¤íŠ¸
result = analyze_sentiment("ì˜¤ëŠ˜ ì‹œí—˜ì„ ì˜ ë´¤ì–´ìš”! ì •ë§ ê¸°ì©ë‹ˆë‹¤.")
print(result)
